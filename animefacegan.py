# -*- coding: utf-8 -*-
"""AnimeFaceGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10SLI_YAv3xCZzhc72Pf53yFozUxVaEep
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import os
import pickle
import h5py
from sklearn.preprocessing import StandardScaler
# %matplotlib inline

import tensorflow as tf
import keras
import keras.layers as L
from keras.layers import Dense
from keras.layers import Reshape
from keras.layers.core import Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import UpSampling2D
from keras.layers.core import Flatten, Dropout
from keras.layers import Input, merge
from keras.layers.pooling import MaxPooling2D
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model
from keras.optimizers import SGD, Adam, RMSprop
from keras.layers.advanced_activations import LeakyReLU
from keras.models import load_model,Sequential
import keras.backend as K
from keras.initializers import RandomNormal

arr = cv2.imread("/content/drive/My Drive/AnimeCharacterDataset/data/face_0_119_15.png")
arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)
arr = cv2.resize(arr,(64,64)) 
X_train=np.vstack([arr[np.newaxis,...]])
plt.imshow(X_train[0])

for img in os.listdir("/content/drive/My Drive/AnimeCharacterDataset/data"):
    arr = cv2.imread("/content/drive/My Drive/AnimeCharacterDataset/data/"+str(img))
    arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)
    arr = cv2.resize(arr,(64,64))
    X_train=np.vstack([X_train,arr[np.newaxis,...] ])

plt.imshow(X_train[18])

with open("/content/drive/My Drive/AnimeCharacterDataset/real_data.pkl","rb") as f:
    X_train = pickle.load(f)

X_train = X_train/255.0

s=tf.InteractiveSession()

gen_model = Sequential()

gen_model.add(Dense(input_dim=100, output_dim=2048))
gen_model.add(LeakyReLU(alpha=0.2))

gen_model.add(Dense(256 * 8 * 8))
gen_model.add(BatchNormalization())
gen_model.add(LeakyReLU(alpha=0.2))

gen_model.add(Reshape((8, 8, 256), input_shape=(256 * 8 * 8,)))
gen_model.add(UpSampling2D(size=(2, 2)))

gen_model.add(Conv2D(128, (5, 5), padding='same'))
gen_model.add(LeakyReLU(alpha=0.2))

gen_model.add(UpSampling2D(size=(2, 2)))

gen_model.add(Conv2D(64, (5, 5), padding='same'))
gen_model.add(LeakyReLU(alpha=0.2))

gen_model.add(UpSampling2D(size=(2, 2)))

gen_model.add(Conv2D(3, (5, 5), padding='same'))
gen_model.add(LeakyReLU(alpha=0.2))

gen_model.summary()

dis_model = Sequential()

dis_model.add(Conv2D(128, (5, 5),padding='same',input_shape=(64, 64, 3)))
dis_model.add(LeakyReLU(alpha=0.2))
dis_model.add(MaxPooling2D(pool_size=(2, 2)))

dis_model.add(Conv2D(256, (3, 3)))
dis_model.add(LeakyReLU(alpha=0.2))
dis_model.add(MaxPooling2D(pool_size=(2, 2)))

dis_model.add(Conv2D(512, (3, 3)))
dis_model.add(LeakyReLU(alpha=0.2))
dis_model.add(MaxPooling2D(pool_size=(2, 2)))

dis_model.add(Flatten())
dis_model.add(Dense(1024))
dis_model.add(LeakyReLU(alpha=0.2))

dis_model.add(L.Dense(2,activation=tf.nn.log_softmax))

dis_model.summary()

IMG_SHAPE = X_train.shape[1:]
CODE_SIZE = 100

noise = tf.placeholder('float32',[None,CODE_SIZE])
real_data = tf.placeholder('float32',[None,]+list(IMG_SHAPE))

logp_real = dis_model(real_data)

generated_data = gen_model(noise)

logp_gen = dis_model(generated_data)

##discriminator training##

d_loss = -tf.reduce_mean(logp_real[:,1] + logp_gen[:,0])
  
#regularize
d_loss += tf.reduce_mean(dis_model.layers[-1].kernel**2)

#optimize
disc_optimizer = tf.train.GradientDescentOptimizer(1e-3).minimize(d_loss,var_list=dis_model.trainable_weights)

##generator training##

g_loss = -tf.reduce_mean(1-logp_gen[:,0])

gen_optimizer = tf.train.AdamOptimizer(1e-4).minimize(g_loss,var_list=gen_model.trainable_weights)

s.run(tf.global_variables_initializer())

total_epoch = 20000

def sample_noise_batch(bsize):
    return np.random.normal(size=(bsize, 100)).astype('float32')

def sample_data_batch(bsize):
    idxs = np.random.choice(np.arange(X_train.shape[0]), size=bsize)
    return X_train[idxs]

def sample_images(nrow,ncol, sharp=False):
    images = gen_model.predict(sample_noise_batch(bsize=nrow*ncol))
    if np.var(images)!=0:
        images = images.clip(np.min(X_train),np.max(X_train))
    for i in range(nrow*ncol):
        plt.subplot(nrow,ncol,i+1)
        if sharp:
            plt.imshow(images[i].reshape(IMG_SHAPE),cmap="gray", interpolation="none")
        else:
            plt.imshow(images[i].reshape(IMG_SHAPE),cmap="gray")
    plt.show()

from IPython import display

for epoch in range(total_epoch):
    feed_dict={
        real_data: sample_data_batch(100),
        noise: sample_noise_batch(100)
    }
    
    for i in range(5):
        s.run(disc_optimizer,feed_dict)
    
    s.run(gen_optimizer,feed_dict)
    
    if epoch%100==0:
        display.clear_output(wait=True)
        sample_images(2,3,True)

gen_model.save("gen_model.h5")
dis_model.save("dis_model.h5")

